{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification in JAX using `TrainState`\n",
    "\n",
    "> It was easier to follow the guide before trying to turn it into something different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 12:28:31.204444: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-04-26 12:28:31.258188: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-26 12:28:33.023032: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.set_visible_devices([], device_type='GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Sequence, Union\n",
    "import numpy as np\n",
    "\n",
    "import jax\n",
    "from jax import lax, random, numpy as jnp\n",
    "from flax.core import freeze, unfreeze\n",
    "from flax import linen as nn\n",
    "from flax import struct\n",
    "from flax.training import train_state\n",
    "\n",
    "import optax\n",
    "\n",
    "from clu import metrics\n",
    "from ml_collections import ConfigDict\n",
    "\n",
    "from einops import reduce\n",
    "\n",
    "from iqadatasets.datasets import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data\n",
    "\n",
    "> We'll be using MNIST from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (60000,), (10000, 28, 28, 1), (10000,))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train, Y_train), (X_test, Y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "X_train = X_train[:,:,:,None]/255.0\n",
    "X_test = X_test[:,:,:,None]/255.0\n",
    "Y_train = Y_train.astype(np.int32)\n",
    "Y_test = Y_test.astype(np.int32)\n",
    "\n",
    "X_train.shape, Y_train.shape, X_test.shape, Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_train = tf.data.Dataset.from_tensor_slices((X_train, Y_train))\n",
    "dst_val = tf.data.Dataset.from_tensor_slices((X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BATCH_SIZE: 256\n",
       "EPOCHS: 50\n",
       "LEARNING_RATE: 0.0003"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\n",
    "    \"BATCH_SIZE\": 256,\n",
    "    \"EPOCHS\": 50,\n",
    "    \"LEARNING_RATE\": 3e-4,\n",
    "}\n",
    "config = ConfigDict(config)\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dst_train_rdy = dst_train.batch(config.BATCH_SIZE)\n",
    "dst_val_rdy = dst_val.batch(config.BATCH_SIZE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the model we're going to use\n",
    "\n",
    "> It's going to be a very simple model just for demonstration purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self,\n",
    "                 inputs,\n",
    "                 **kwargs,\n",
    "                 ):\n",
    "        outputs = nn.Conv(features=32, kernel_size=(3,3))(inputs)\n",
    "        outputs = nn.relu(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = nn.Conv(features=64, kernel_size=(3,3))(outputs)\n",
    "        outputs = nn.relu(outputs)\n",
    "        outputs = nn.max_pool(outputs, window_shape=(2,2), strides=(2,2))\n",
    "        outputs = reduce(outputs, \"b h w c -> b c\", reduction=\"mean\")\n",
    "        outputs = nn.Dense(10)(outputs)\n",
    "        return outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the metrics with `clu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    \"\"\"Collection of metrics to be tracked during training.\"\"\"\n",
    "    accuracy: metrics.Accuracy\n",
    "    loss: metrics.Average.from_output(\"loss\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `TrainState` doesn't include metrics, but it's very easy to subclass it so that it does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a function that initializes the `TrainState` from a module, a rng key and some optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(module, key, tx, input_shape):\n",
    "    \"\"\"Creates the initial `TrainState`.\"\"\"\n",
    "    params = module.init(key, jnp.ones(input_shape))[\"params\"]\n",
    "    return TrainState.create(\n",
    "        apply_fn=module.apply,\n",
    "        params=params,\n",
    "        tx=tx,\n",
    "        metrics=Metrics.empty()\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the training step\n",
    "\n",
    "> We want to write a function that takes the `TrainState` and a batch of data can performs an optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "    inputs, labels = batch\n",
    "    def loss(params):\n",
    "        pred = state.apply_fn({\"params\": params}, inputs)\n",
    "        loss = optax.softmax_cross_entropy_with_integer_labels(logits=pred, labels=labels).mean()\n",
    "        return loss\n",
    "    grads = jax.grad(loss)(state.params)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In their example, they don't calculate the metrics at the same time. I think it is kind of a waste because it means having to perform a new forward pass, but we'll follow as of now. Let's define a function to perform metric calculation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def compute_metrics(*, state, batch):\n",
    "    \"\"\"Obtaining the metrics for a given batch.\"\"\"\n",
    "    inputs, labels = batch\n",
    "    pred = state.apply_fn({\"params\": state.params}, inputs)\n",
    "    loss = optax.softmax_cross_entropy_with_integer_labels(logits=pred, labels=labels).mean()\n",
    "    metric_updates = state.metrics.single_from_model_output(\n",
    "        logits=pred, labels=labels, loss=loss,\n",
    "    )\n",
    "    metrics = state.metrics.merge(metric_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "    return state"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = create_train_state(Model(), random.PRNGKey(0), optax.adam(config.LEARNING_RATE), input_shape=(1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_history = {\n",
    "    \"train_loss\": [],\n",
    "    \"val_loss\": [],\n",
    "    \"train_accuracy\": [],\n",
    "    \"val_accuracy\": [],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -> [Train] Loss: 2.179863691329956 | Accuracy: 0.26034998893737793 [Val] Loss: 1.9363536834716797 | Accuracy: 0.4207000136375427\n",
      "Epoch 1 -> [Train] Loss: 1.6733933687210083 | Accuracy: 0.501966655254364 [Val] Loss: 1.4757570028305054 | Accuracy: 0.5743000507354736\n",
      "Epoch 2 -> [Train] Loss: 1.3742271661758423 | Accuracy: 0.5971333384513855 [Val] Loss: 1.263370394706726 | Accuracy: 0.6460000276565552\n",
      "Epoch 3 -> [Train] Loss: 1.2035051584243774 | Accuracy: 0.6574167013168335 [Val] Loss: 1.11570143699646 | Accuracy: 0.6895000338554382\n",
      "Epoch 4 -> [Train] Loss: 1.0782545804977417 | Accuracy: 0.6978999972343445 [Val] Loss: 1.0012279748916626 | Accuracy: 0.7230000495910645\n",
      "Epoch 5 -> [Train] Loss: 0.9798782467842102 | Accuracy: 0.7282666563987732 [Val] Loss: 0.9096516966819763 | Accuracy: 0.7509000301361084\n",
      "Epoch 6 -> [Train] Loss: 0.9003434777259827 | Accuracy: 0.7511667013168335 [Val] Loss: 0.8355976343154907 | Accuracy: 0.7704000473022461\n",
      "Epoch 7 -> [Train] Loss: 0.8347769975662231 | Accuracy: 0.7699000239372253 [Val] Loss: 0.7737947702407837 | Accuracy: 0.7861000299453735\n",
      "Epoch 8 -> [Train] Loss: 0.7795228362083435 | Accuracy: 0.7852333188056946 [Val] Loss: 0.7216793894767761 | Accuracy: 0.8015000224113464\n",
      "Epoch 9 -> [Train] Loss: 0.7322704195976257 | Accuracy: 0.7983333468437195 [Val] Loss: 0.6768896579742432 | Accuracy: 0.8161000609397888\n",
      "Epoch 10 -> [Train] Loss: 0.6911123394966125 | Accuracy: 0.8096333146095276 [Val] Loss: 0.6379691958427429 | Accuracy: 0.8264000415802002\n",
      "Epoch 11 -> [Train] Loss: 0.6547446846961975 | Accuracy: 0.8193166851997375 [Val] Loss: 0.6034817099571228 | Accuracy: 0.835800051689148\n",
      "Epoch 12 -> [Train] Loss: 0.6221888065338135 | Accuracy: 0.8286833167076111 [Val] Loss: 0.5728276371955872 | Accuracy: 0.8444000482559204\n",
      "Epoch 13 -> [Train] Loss: 0.592809796333313 | Accuracy: 0.8369500041007996 [Val] Loss: 0.545353353023529 | Accuracy: 0.8529000282287598\n",
      "Epoch 14 -> [Train] Loss: 0.5661748647689819 | Accuracy: 0.8441833257675171 [Val] Loss: 0.5206612348556519 | Accuracy: 0.8607000112533569\n",
      "Epoch 15 -> [Train] Loss: 0.5418640971183777 | Accuracy: 0.8511666655540466 [Val] Loss: 0.49828776717185974 | Accuracy: 0.8664000630378723\n",
      "Epoch 16 -> [Train] Loss: 0.5196174383163452 | Accuracy: 0.8570833206176758 [Val] Loss: 0.4779704213142395 | Accuracy: 0.8706000447273254\n",
      "Epoch 17 -> [Train] Loss: 0.4991525709629059 | Accuracy: 0.8631166815757751 [Val] Loss: 0.4595378041267395 | Accuracy: 0.8741000294685364\n",
      "Epoch 18 -> [Train] Loss: 0.4803047478199005 | Accuracy: 0.8684833645820618 [Val] Loss: 0.44265756011009216 | Accuracy: 0.8782000541687012\n",
      "Epoch 19 -> [Train] Loss: 0.4629392623901367 | Accuracy: 0.8734166622161865 [Val] Loss: 0.4272184371948242 | Accuracy: 0.8815000653266907\n",
      "Epoch 20 -> [Train] Loss: 0.44692835211753845 | Accuracy: 0.8776833415031433 [Val] Loss: 0.41302505135536194 | Accuracy: 0.8848000168800354\n",
      "Epoch 21 -> [Train] Loss: 0.4320833683013916 | Accuracy: 0.8814666867256165 [Val] Loss: 0.4000661075115204 | Accuracy: 0.8880000710487366\n",
      "Epoch 22 -> [Train] Loss: 0.41831517219543457 | Accuracy: 0.884850025177002 [Val] Loss: 0.38810011744499207 | Accuracy: 0.8910000324249268\n",
      "Epoch 23 -> [Train] Loss: 0.40555620193481445 | Accuracy: 0.8883000016212463 [Val] Loss: 0.37713727355003357 | Accuracy: 0.8941000699996948\n",
      "Epoch 24 -> [Train] Loss: 0.3936755955219269 | Accuracy: 0.8917999863624573 [Val] Loss: 0.3669348657131195 | Accuracy: 0.8962000608444214\n",
      "Epoch 25 -> [Train] Loss: 0.38261884450912476 | Accuracy: 0.8945500254631042 [Val] Loss: 0.35752519965171814 | Accuracy: 0.8974000215530396\n",
      "Epoch 26 -> [Train] Loss: 0.3723006844520569 | Accuracy: 0.897016704082489 [Val] Loss: 0.3487200438976288 | Accuracy: 0.8986000418663025\n",
      "Epoch 27 -> [Train] Loss: 0.36266595125198364 | Accuracy: 0.8993666768074036 [Val] Loss: 0.34057819843292236 | Accuracy: 0.9010000228881836\n",
      "Epoch 28 -> [Train] Loss: 0.35366111993789673 | Accuracy: 0.9014166593551636 [Val] Loss: 0.3329307734966278 | Accuracy: 0.9025000333786011\n",
      "Epoch 29 -> [Train] Loss: 0.34524428844451904 | Accuracy: 0.9036999940872192 [Val] Loss: 0.325786292552948 | Accuracy: 0.9038000702857971\n",
      "Epoch 30 -> [Train] Loss: 0.3373560309410095 | Accuracy: 0.9056666493415833 [Val] Loss: 0.3190995752811432 | Accuracy: 0.9052000641822815\n",
      "Epoch 31 -> [Train] Loss: 0.3299282193183899 | Accuracy: 0.9071666598320007 [Val] Loss: 0.31279483437538147 | Accuracy: 0.9064000248908997\n",
      "Epoch 32 -> [Train] Loss: 0.3229246437549591 | Accuracy: 0.9087333679199219 [Val] Loss: 0.3067791163921356 | Accuracy: 0.9082000255584717\n",
      "Epoch 33 -> [Train] Loss: 0.316310852766037 | Accuracy: 0.9103000164031982 [Val] Loss: 0.3012504279613495 | Accuracy: 0.9094000458717346\n",
      "Epoch 34 -> [Train] Loss: 0.3100613057613373 | Accuracy: 0.9118666648864746 [Val] Loss: 0.29597610235214233 | Accuracy: 0.9111000299453735\n",
      "Epoch 35 -> [Train] Loss: 0.30415719747543335 | Accuracy: 0.913349986076355 [Val] Loss: 0.2908722162246704 | Accuracy: 0.9120000600814819\n",
      "Epoch 36 -> [Train] Loss: 0.2985559105873108 | Accuracy: 0.9148666858673096 [Val] Loss: 0.2861136496067047 | Accuracy: 0.9140000343322754\n",
      "Epoch 37 -> [Train] Loss: 0.2932088375091553 | Accuracy: 0.9163833260536194 [Val] Loss: 0.28155517578125 | Accuracy: 0.9150000214576721\n",
      "Epoch 38 -> [Train] Loss: 0.2881231904029846 | Accuracy: 0.9179166555404663 [Val] Loss: 0.2772302031517029 | Accuracy: 0.9162000417709351\n",
      "Epoch 39 -> [Train] Loss: 0.2832687199115753 | Accuracy: 0.9191666841506958 [Val] Loss: 0.2730538249015808 | Accuracy: 0.9175000190734863\n",
      "Epoch 40 -> [Train] Loss: 0.2786351144313812 | Accuracy: 0.9204166531562805 [Val] Loss: 0.26905083656311035 | Accuracy: 0.9188000559806824\n",
      "Epoch 41 -> [Train] Loss: 0.2742093503475189 | Accuracy: 0.9217333197593689 [Val] Loss: 0.26526781916618347 | Accuracy: 0.9198000431060791\n",
      "Epoch 42 -> [Train] Loss: 0.26996535062789917 | Accuracy: 0.9227166771888733 [Val] Loss: 0.26161062717437744 | Accuracy: 0.921000063419342\n",
      "Epoch 43 -> [Train] Loss: 0.26588964462280273 | Accuracy: 0.9237833619117737 [Val] Loss: 0.258030503988266 | Accuracy: 0.9226000308990479\n",
      "Epoch 44 -> [Train] Loss: 0.26196348667144775 | Accuracy: 0.9247666597366333 [Val] Loss: 0.25455671548843384 | Accuracy: 0.9237000346183777\n",
      "Epoch 45 -> [Train] Loss: 0.25818783044815063 | Accuracy: 0.9259999990463257 [Val] Loss: 0.2512337863445282 | Accuracy: 0.9246000647544861\n",
      "Epoch 46 -> [Train] Loss: 0.2545514404773712 | Accuracy: 0.926800012588501 [Val] Loss: 0.24799060821533203 | Accuracy: 0.9257000684738159\n",
      "Epoch 47 -> [Train] Loss: 0.2510388195514679 | Accuracy: 0.9277666807174683 [Val] Loss: 0.24487821757793427 | Accuracy: 0.9269000291824341\n",
      "Epoch 48 -> [Train] Loss: 0.24765527248382568 | Accuracy: 0.9287333488464355 [Val] Loss: 0.24188826978206635 | Accuracy: 0.9278000593185425\n",
      "Epoch 49 -> [Train] Loss: 0.24437624216079712 | Accuracy: 0.9296333193778992 [Val] Loss: 0.2388812154531479 | Accuracy: 0.9284000396728516\n",
      "CPU times: user 1min 14s, sys: 9.94 s, total: 1min 24s\n",
      "Wall time: 29.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(config.EPOCHS):\n",
    "    ## Training\n",
    "    for batch in dst_train_rdy.as_numpy_iterator():\n",
    "        state = train_step(state, batch)\n",
    "        state = compute_metrics(state=state, batch=batch)\n",
    "        # break\n",
    "\n",
    "    ## Log the metrics\n",
    "    for name, value in state.metrics.compute().items():\n",
    "        metrics_history[f\"train_{name}\"].append(value)\n",
    "    \n",
    "    ## Empty the metrics\n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "\n",
    "    ## Evaluation\n",
    "    for batch in dst_val_rdy.as_numpy_iterator():\n",
    "        state = compute_metrics(state=state, batch=batch)\n",
    "        # break\n",
    "    for name, value in state.metrics.compute().items():\n",
    "        metrics_history[f\"val_{name}\"].append(value)\n",
    "    state = state.replace(metrics=state.metrics.empty())\n",
    "    \n",
    "    print(f'Epoch {epoch} -> [Train] Loss: {metrics_history[\"train_loss\"][-1]} | Accuracy: {metrics_history[\"train_accuracy\"][-1]} [Val] Loss: {metrics_history[\"val_loss\"][-1]} | Accuracy: {metrics_history[\"val_accuracy\"][-1]}')\n",
    "    # break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
